# OpenAI API Proxy

En FastAPI-basert proxy for OpenAI's API med st√∏tte for streaming, token-h√•ndtering og automatisk modell-validering. Designet for enkel deployment p√• Railway.app.

## Funksjoner

- üöÄ Full streaming-st√∏tte for ChatGPT-responser
- üìä Automatisk token-h√•ndtering og justering
- ‚úÖ Validering av modeller og parametre
- üîÑ CORS-st√∏tte for web-integrasjoner
- üè• Innebygd helsesjekk-endepunkt
- üìù Detaljert logging
- üê≥ Docker-st√∏tte

## API Endepunkter

- `POST /v1/chat/completions` - Hoved-endepunkt for chat completions
- `GET /health` - Helsesjekk-endepunkt
- `GET /` - API informasjon

## Oppsett

### Forutsetninger

- Python 3.9 eller nyere
- OpenAI API-n√∏kkel
- Git
- Docker (valgfritt)

### Milj√∏variabler

```env
OPENAI_API_KEY=din-api-n√∏kkel-her
PORT=8000  # Valgfri, standard er 8000
```

### Lokal Kj√∏ring

1. Klon repositoriet:
```bash
git clone [repo-url]
cd [repo-navn]
```

2. Installer avhengigheter:
```bash
pip install -r requirements.txt
```

3. Opprett `.env` fil med din OpenAI API-n√∏kkel:
```env
OPENAI_API_KEY=din-api-n√∏kkel-her
```

4. Kj√∏r applikasjonen:
```bash
python main.py
```

### Docker Kj√∏ring

1. Bygg Docker image:
```bash
docker build -t openai-proxy .
```

2. Kj√∏r container:
```bash
docker run -p 8000:8000 -e OPENAI_API_KEY=din-api-n√∏kkel-her openai-proxy
```

## Deployment p√• Railway

1. Fork eller push dette repositoriet til GitHub
2. Koble til Railway.app med GitHub
3. Velg repositoriet i Railway
4. Legg til milj√∏variabel i Railway:
   - `OPENAI_API_KEY`: Din OpenAI API-n√∏kkel
5. Deploy!

## Bruk

### Eksempel p√• foresp√∏rsel

```python
import requests
import json

url = "din-railway-url/v1/chat/completions"
headers = {
    "Content-Type": "application/json"
}

data = {
    "model": "gpt-3.5-turbo",
    "messages": [
        {
            "role": "user",
            "content": "Hei, hvordan har du det?"
        }
    ],
    "temperature": 0.7
}

response = requests.post(url, headers=headers, json=data)
print(json.dumps(response.json(), indent=2))
```

### Streaming Eksempel

```python
import requests

url = "din-railway-url/v1/chat/completions"
headers = {
    "Content-Type": "application/json"
}

data = {
    "model": "gpt-3.5-turbo",
    "messages": [
        {
            "role": "user",
            "content": "Fortell meg en historie"
        }
    ],
    "stream": True
}

response = requests.post(url, headers=headers, json=data, stream=True)
for line in response.iter_lines():
    if line:
        print(line.decode('utf-8'))
```

## St√∏ttede Modeller

- gpt-4
- gpt-4-32k
- gpt-3.5-turbo
- gpt-3.5-turbo-16k

## Feils√∏king

### Vanlige Feil

1. **"OpenAI API key not found"**
   - Sjekk at OPENAI_API_KEY er satt korrekt i milj√∏variabler

2. **"Model not found"**
   - Verifiser at du bruker en st√∏ttet modell

3. **"Token limit exceeded"**
   - Reduser lengden p√• meldingene eller juster max_tokens

### Logging

Applikasjonen logger til stdout med detaljert informasjon om feil og foresp√∏rsler.

## Bidrag

Bidrag er velkomne! Vennligst f√∏lg disse stegene:

1. Fork repositoriet
2. Opprett en feature branch
3. Commit endringene dine
4. Push til branchen
5. √Öpne en Pull Request

## Lisens

Dette prosjektet er lisensiert under MIT Lisens.
